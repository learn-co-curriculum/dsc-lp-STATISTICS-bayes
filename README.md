---
title: 
layout: post
weight: 10
hidden: true
---

===


**Course**: DS   <br/>
**Mod**: Mod 3 Sec 23 V2         <br/>
**Topic**:  Bayes Theorem and Naive Bayes Classifiers  <br/>
**Amount of time**: ~60 minutes <br/>
**Author**: Matt Mitchell


***

#### Lesson Summary:

This lesson reviews section 23. Students should have already complete the accompanying readings and attempted the labs. The lesson begins by asking students to compute the conditional probability of an individual being a Democrat given some prior information regarding them and statistics surrounding the scenario. From there, a data set is introduced which mirrors and extends this initial word problem. Students are asked how they could apply a Naive Bayes Classifier to this datset, extending the intuition behind the original word problem which started the lesson. From there, students are asked to compare and contrast Bayesian Classifiers such as the Gaussian Naive Bayes Classifier and the Bernoulli Naive Bayes Classifier. (These implementations differ based on the nature of the underlying variables they model. Specifically, there is a large divide between how to handle continuous versus categorical variables.)  Finally, students are asked to debug a Naive Bayes Classifier Implementation. The source of this error revolves around the problem of a test case which does not have an associated example from the training set. This also raises the interesting question of how to handle said cases; assigning this case zero probability will force the classifier to ignore all other data regarding this sample, so arbitrarily choosing a small but positive nonzero probability is a typical solution.

#### Topic:

Statistics: Bayes Theorem and Naive Bayes Classifiers

#### Prerequisite knowledge:

* Students should be able to calculate and apply conditional probability to word problems.
* Students should be able to define and apply Bayes' Theorem
* Students should have exposure to Naive Bayes Classifiers and their python implementations

#### Prequisite Learn-Materials:

[Bayes' Theorem](https://github.com/learn-co-curriculum/dsc-bayes-theorem)
[Bayes' Theorem - Lab](https://github.com/learn-co-curriculum/dsc-bayes-theorem-lab)

[The Monty Hall Problem - Lab](https://github.com/learn-co-curriculum/dsc-monty-hall-problem-lab)


[Bayesians vs Frequentists](https://github.com/learn-co-curriculum/dsc-bayesians-vs-frequentists)
[Classifiers with Bayes](https://github.com/learn-co-curriculum/dsc-classifiers-with-bayes)
[Gaussian Naive Bayes](https://github.com/learn-co-curriculum/dsc-gaussian-naive-bayes)
[Gaussian Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-gaussian-naive-bayes-lab)
[Document Classification with Naive Bayes](https://github.com/learn-co-curriculum/dsc-document-classification-with-naive-bayes)
[Document Classification with Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-document-classification-with-naive-bayes-lab)


Recommended but more supplementary:
[Maximum Likelihood Estimation (MLE)](https://github.com/learn-co-curriculum/dsc-mle)
[Maximum A Posteriori Estimation (MAP) and Multinomial Bayes](https://github.com/learn-co-curriculum/dsc-map-multinomial-bayes)

#### Post Learn-Materials:

It is recommended that students attempt these labs before class, but they can return to these lessons to further engage with the material from this lesson.

[Bayes' Theorem - Lab](https://github.com/learn-co-curriculum/dsc-bayes-theorem-lab)
[Gaussian Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-gaussian-naive-bayes-lab)
[Document Classification with Naive Bayes - Lab](https://github.com/learn-co-curriculum/dsc-document-classification-with-naive-bayes-lab)



#### Learning goals for this lesson:


* Students will be able to apply Bayes Theorem to a word problem.
* Students will be able to compare and contrast Bayes Classifiers including Gaussian Naive Bayes and Bernoulli Naive Bayes.
* Students will be able to explain python code for implementing a Naive Bayes Classifier.


#### Relevant learning goals from Airtable: 

BAYES.1.rec4dX6d6f1cMFbcn Define Bayes Theorem in relation to conditional probabilities
BAYES.2.recHQkTu9DmwBs9Oj Use Bayes' Theorem to determine the probability of specific events
BAYES.2.recfnnQ5l74dxvAsD Identify examples of applications of Bayes' Theorem
BAYES.2.recfEgSB5kmXQQY0w Explain how to use the probabilities generated by Naive Bayes to make a classification
BAYES.2.recrWYWSfiarh0TTO Implement the Gaussian Naive Bayes Algorithm using numpy and scipy
BAYES.3.rec9xyzJewoWuvNrj Implement document classification using Naive Bayes


#### Materials
- Ipython notebook

#### Vocab / Concepts 

* Bayes Theorem
* Conditional Probability

#### Lesson Outline:

* Introduction (2 minutes)
* Conditional Probabilities Warm-Up Question 15 minutes)

* Defining a Classification Problem (5+ minutes)
* Gaussian Naive Bayes vs. Bernoulli Naive Bayes
	* Continuous Variables vs Categorial Variables (10 minutes)
	* Review coding of Bernoulli Naive Bayes (15 minutes)
		* Debugging / Handling Cases Unseen in Training 
* Summary (5 minutes)